{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8b4e84b-a787-43a5-9d8f-e9c8285d9d54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10298,
     "status": "ok",
     "timestamp": 1681385348517,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "d8b4e84b-a787-43a5-9d8f-e9c8285d9d54",
    "outputId": "059611f9-7b06-48f7-c925-575610cddbdf"
   },
   "outputs": [],
   "source": [
    "#!pip install python_terrier\n",
    "#!pip install krovetzstemmer\n",
    "\n",
    "import numpy as np\n",
    "import math as mt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f1c31-4ce1-49d1-8b32-157d94aa1d7b",
   "metadata": {
    "id": "a58f1c31-4ce1-49d1-8b32-157d94aa1d7b"
   },
   "source": [
    "# DATA COLLECTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c48fe03-928f-4def-b8dd-b487a5225fb7",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1681385348518,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "8c48fe03-928f-4def-b8dd-b487a5225fb7"
   },
   "outputs": [],
   "source": [
    "msmarco_document = pt.datasets.get_dataset(\"msmarco_document\")\n",
    "msmarcov2_document = pt.datasets.get_dataset(\"msmarcov2_document\")\n",
    "msmarco_passage = pt.datasets.get_dataset(\"msmarco_passage\")\n",
    "msmarcov2_passage = pt.datasets.get_dataset(\"msmarcov2_passage\")\n",
    "vaswani = pt.datasets.get_dataset(\"vaswani\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb94100-4638-4dce-ac4b-50cd6869eaba",
   "metadata": {
    "id": "cbb94100-4638-4dce-ac4b-50cd6869eaba"
   },
   "source": [
    "# RETRIEVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jSQ31cSWvC9I",
   "metadata": {
    "id": "jSQ31cSWvC9I"
   },
   "source": [
    "KROVETZSTEMMER \n",
    "Its effectiveness is comparable to the Porter stemmer. It has a lower false positive rate, but somewhat higher false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "btINCYm2uQ9u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681385348518,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "btINCYm2uQ9u",
    "outputId": "4bcd198c-6d12-49a9-ce79-7c97505687ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utility'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from krovetzstemmer import Stemmer\n",
    "krovetz = Stemmer()\n",
    "krovetz.stem('utilities') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c5341-0999-419b-856d-ca19fc1cb840",
   "metadata": {
    "id": "c24c5341-0999-419b-856d-ca19fc1cb840"
   },
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95a10620-836b-4fb6-84ab-0e769cc6aca6",
   "metadata": {
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1681385348909,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "95a10620-836b-4fb6-84ab-0e769cc6aca6"
   },
   "outputs": [],
   "source": [
    "#Check InQuery Stop List\n",
    "def remove_stopwords(token_text):\n",
    "    stops = stopwords.words('english')\n",
    "    new_tokentext = []\n",
    "    for word in token_text:\n",
    "        if word not in stops:\n",
    "            new_tokentext.append(word)\n",
    "    return new_tokentext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2ec1b40-c931-45b4-8bee-065b255412c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1681385348909,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "b2ec1b40-c931-45b4-8bee-065b255412c0"
   },
   "outputs": [],
   "source": [
    "#Majuscule et ponctuation, CHECK NUMBERS et mot d'une lettre\n",
    "def preproc(coll):\n",
    "    for docno in coll.keys():\n",
    "        tmp = remove_stopwords(RegexpTokenizer(r'\\w+').tokenize(coll[docno].lower())) # lower + remove punc + remove stopwords\n",
    "        tmp2 = []\n",
    "        for j in range(len(tmp)):\n",
    "            if(len(tmp[j])>1 and not tmp[j].isnumeric() ): # + d'une lettre et pas un nombre\n",
    "                tmp2.append(krovetz.stem(tmp[j]))\n",
    "        coll[docno] = tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23d3d1d2-5469-4193-a0c2-671fbe0503d1",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1681385348910,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "23d3d1d2-5469-4193-a0c2-671fbe0503d1"
   },
   "outputs": [],
   "source": [
    "# 1000 mots les plus fréquents des documents + requetes\n",
    "def top_vocab(coll, queries, top_terms=1000):\n",
    "    list_words = []\n",
    "    for docno in coll.keys():\n",
    "        list_words += coll[docno]\n",
    "    \n",
    "    for q_id in queries.keys():\n",
    "        list_words += queries[q_id]\n",
    "    \n",
    "    if top_terms==None:\n",
    "        return list_words\n",
    "    else:\n",
    "        return dict(Counter(list_words).most_common(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1169d8e6-2d29-4dfe-a90e-2ad9ac22b7e0",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1681385348910,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "1169d8e6-2d29-4dfe-a90e-2ad9ac22b7e0"
   },
   "outputs": [],
   "source": [
    "# Reformule les docs/requetes selon les 1000 mots les + fréquents\n",
    "def truncate(coll, queries, top_terms=1000):\n",
    "    vocabulary = list(top_vocab(coll, queries, top_terms).keys())\n",
    "    for docno in coll.keys():\n",
    "        tmp = coll[docno]\n",
    "        new_doc = []\n",
    "        for word in tmp:\n",
    "            if word in vocabulary:\n",
    "                new_doc.append(word)\n",
    "        coll[docno] = new_doc\n",
    "        \n",
    "    for q_id in queries.keys():\n",
    "        tmp = queries[q_id]\n",
    "        new_query = []\n",
    "        for word in tmp:\n",
    "            if word in vocabulary:\n",
    "                new_query.append(word)\n",
    "        queries[q_id] = new_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e74ecc10-5684-481d-90d3-b6ca282d9e2a",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681385348910,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "e74ecc10-5684-481d-90d3-b6ca282d9e2a"
   },
   "outputs": [],
   "source": [
    "#Term frequency pour un doc de la collection\n",
    "def tf_dict(coll, docno):\n",
    "    tf = dict()\n",
    "    for word in coll[docno]:\n",
    "        if word not in tf.keys():\n",
    "            tf[word] = 1\n",
    "        else:\n",
    "            tf[word] += 1\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4dbb37e9-4de6-4dca-bf30-7da378b477b9",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681385348910,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "4dbb37e9-4de6-4dca-bf30-7da378b477b9"
   },
   "outputs": [],
   "source": [
    "#Term frequency pour tous les docs de la collection (dictionnaire de dictionnaire {1 : {mot : 3, ...}} )\n",
    "def dict_alldocs(coll):\n",
    "    dictTF_alldocs = dict()\n",
    "    for docno in coll.keys():\n",
    "        dictTF_alldocs[docno] = tf_dict(coll, docno)\n",
    "    return dictTF_alldocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "072590ad-02d4-4542-9228-99005237e1b5",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681385348911,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "072590ad-02d4-4542-9228-99005237e1b5"
   },
   "outputs": [],
   "source": [
    "#Nb mot pour un document\n",
    "def term_occ(coll, docno):\n",
    "    return len(coll[docno])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab8fd1-8d03-4747-acde-80c9ce99a466",
   "metadata": {
    "id": "84ab8fd1-8d03-4747-acde-80c9ce99a466"
   },
   "source": [
    "## UNEXPANDED RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7610d08d-268d-4180-b67d-74e89c5d3feb",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681385348911,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "7610d08d-268d-4180-b67d-74e89c5d3feb"
   },
   "outputs": [],
   "source": [
    "#P_ml, number of times \"w\" occurs in document D divided by the number of term occurrences in D\n",
    "def p_ml(dictTF_alldocs, coll, w, docno):\n",
    "    if w not in coll[docno]:\n",
    "        return 0\n",
    "    else:\n",
    "        return dictTF_alldocs[docno][w] / term_occ(coll, docno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6c2f1bce-43cc-4c38-a4af-14828879aed3",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681385348911,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "6c2f1bce-43cc-4c38-a4af-14828879aed3"
   },
   "outputs": [],
   "source": [
    "#Same but for the entire collection\n",
    "def p_ml_coll(dictTF_alldocs, coll, w):\n",
    "    sum_tf = 0\n",
    "    for docno in coll.keys():\n",
    "        if w in coll[docno]:\n",
    "            sum_tf += dictTF_alldocs[docno][w]\n",
    "            \n",
    "    return sum_tf / sum([term_occ(coll, docno) for docno in coll.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2cba6902-9c12-4af5-b9f4-f0a5c68b10e6",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681385348912,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "2cba6902-9c12-4af5-b9f4-f0a5c68b10e6"
   },
   "outputs": [],
   "source": [
    "def smoothing(dictTF_alldocs, coll, w, docno, lamb): # P(w|D)\n",
    "    return lamb * p_ml(dictTF_alldocs, coll, w, docno) + (1 - lamb) * p_ml_coll(dictTF_alldocs, coll, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c1646acf-46b9-43bd-83c4-c7c738d73384",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681385348912,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "c1646acf-46b9-43bd-83c4-c7c738d73384"
   },
   "outputs": [],
   "source": [
    "def dirichlet_smoothing(dictTF_alldocs, coll, w, docno, mu=1000):\n",
    "    lamb = term_occ(coll, docno) / (term_occ(coll, docno) + mu)\n",
    "    return smoothing(dictTF_alldocs, coll, w, docno, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "607919e3-c228-4131-98ef-cb48c3dcb017",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1681385348912,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "607919e3-c228-4131-98ef-cb48c3dcb017"
   },
   "outputs": [],
   "source": [
    "#P(Q|D)\n",
    "def query_likelihood_retr(dictTF_alldocs, coll, query, docno, prob_func = dirichlet_smoothing): # P(Q|D)\n",
    "    return np.prod(np.array([prob_func(dictTF_alldocs, coll, term, docno) for term in query]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7X9TeHXi9Udc",
   "metadata": {
    "id": "7X9TeHXi9Udc"
   },
   "source": [
    "# TESTTTSTETSTSTTTTEEESSSTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd1e4708-1627-445e-b8ea-d0e897a2d1d4",
   "metadata": {
    "executionInfo": {
     "elapsed": 5982,
     "status": "ok",
     "timestamp": 1681385354886,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "bd1e4708-1627-445e-b8ea-d0e897a2d1d4"
   },
   "outputs": [],
   "source": [
    "# ONLY FOR MINI TESTS ; OFFICIAL DATASET TO USE IS MSMARCO_DOCUMENT\n",
    "queries_l = vaswani.get_topics()['query'].to_list()\n",
    "id_queries = vaswani.get_topics()['qid'].to_list()\n",
    "\n",
    "queries = dict()\n",
    "i=0\n",
    "for id_q in id_queries:\n",
    "    queries[id_q] = queries_l[i]\n",
    "    i += 1\n",
    "\n",
    "coll = dict()\n",
    "for doc in vaswani.get_corpus_iter():\n",
    "    coll[doc['docno']] = doc['text']\n",
    "\n",
    "preproc(coll)\n",
    "preproc(queries)\n",
    "truncate(coll, queries, top_terms=1000)\n",
    "dictTF_alldocs = dict_alldocs(coll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8880a61-743a-4f78-982e-a1d98b115c4c",
   "metadata": {
    "id": "c8880a61-743a-4f78-982e-a1d98b115c4c"
   },
   "source": [
    "## 2.3 EXPANDED RETRIEVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9756c20-2cd0-4358-af02-6e6e55cd3534",
   "metadata": {
    "id": "b9756c20-2cd0-4358-af02-6e6e55cd3534"
   },
   "source": [
    "### 2.3.1 Relevance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7e1e8c42-bb29-4005-9a9d-8572ba6e3187",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1681385358175,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "7e1e8c42-bb29-4005-9a9d-8572ba6e3187"
   },
   "outputs": [],
   "source": [
    "#P(D|Q) = P(Q|D)*P(D)\n",
    "def bayes(dictTF_alldocs, coll, query, docno, prob_func = dirichlet_smoothing): \n",
    "    return query_likelihood_retr(dictTF_alldocs, coll, query, docno, prob_func) * 1/len(coll) # uniformity for P(D), we assume that we have same probs for all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b1cdc801-7ea8-4685-b3e1-87413ddd5a4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1681385358175,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "b1cdc801-7ea8-4685-b3e1-87413ddd5a4d",
    "outputId": "59f206f7-a1c5-4f1c-a492-e755b1905d8b"
   },
   "outputs": [],
   "source": [
    "#print(bayes(dictTF_alldocs, coll, queries['1'], '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2c913f42-9153-4640-9927-0bf6321721c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nqueries_df = queries.copy()\\n\\nfor qid in queries_df.keys():\\n    queries_df[qid] = \" \".join(queries_df[qid])\\n\\ndf_queries = pd.DataFrame(queries_df.items(), columns=[\\'qid\\', \\'query\\'])\\n\\ntop_docs = bm25.transform(df_queries)\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FAIRE INDEX ET RETRIEVING ICI (et bien dire que c'est un ajustement, dire dans le CR que ça manque dans le papier (la manière d'indexer et la manière de retrieve))\n",
    "\n",
    "# VASWANI\n",
    "coll_df = coll.copy()\n",
    "\n",
    "for docno in coll_df.keys():\n",
    "    coll_df[docno] = \" \".join(coll_df[docno])\n",
    "\n",
    "df = pd.DataFrame(coll_df.items(), columns=['docno', 'text'])\n",
    "\n",
    "indexer = pt.DFIndexer(\"./index\")\n",
    "#indexref = indexer.index(df[\"text\"], df[\"docno\"])\n",
    "\n",
    "# index = pt.IndexFactory.of(indexref)\n",
    "index = pt.IndexFactory.of(\"./index/data.properties\")\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\") % 50\n",
    "\n",
    "'''\n",
    "queries_df = queries.copy()\n",
    "\n",
    "for qid in queries_df.keys():\n",
    "    queries_df[qid] = \" \".join(queries_df[qid])\n",
    "\n",
    "df_queries = pd.DataFrame(queries_df.items(), columns=['qid', 'query'])\n",
    "\n",
    "top_docs = bm25.transform(df_queries)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0eee6d19-667e-4c7a-aec2-2cf5834cd60b",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1681385358176,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "0eee6d19-667e-4c7a-aec2-2cf5834cd60b"
   },
   "outputs": [],
   "source": [
    "# P(w|Q) = sum D in R ( P(w|D)*P(D|Q) ) où R est le top50 documents\n",
    "def relevance_model(dictTF_alldocs, retriever, coll, w, query, prob_func=smoothing, lamb=0.9):\n",
    "    top50 = bm25.transform(query)['docno'].to_list()[:50]\n",
    "    \n",
    "    return np.sum(np.array([prob_func(dictTF_alldocs, coll, w, docno, lamb) * bayes(dictTF_alldocs, coll, query, docno) for docno in top50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "726659e1-8ceb-40a6-a7b4-3591bf7d0a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/pyterrier/ops.py:190: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4999567273853614e-26\n"
     ]
    }
   ],
   "source": [
    "print(relevance_model(dictTF_alldocs, bm25, coll, coll['1'][0], queries['1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1e146-b4cd-4bf0-b614-b0d55320203c",
   "metadata": {
    "id": "88a1e146-b4cd-4bf0-b614-b0d55320203c"
   },
   "source": [
    "### 2.3.2 Relevance model retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bbabdf9e-16f8-4e59-b42d-026db609b706",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1681385358176,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "bbabdf9e-16f8-4e59-b42d-026db609b706"
   },
   "outputs": [],
   "source": [
    "# PAS SUR, A VERIFIER\n",
    "def rel_mod_retrieval(dictTF_alldocs, coll, query, docno, prob_func=smoothing, lamb=0.2):  \n",
    "    model = []\n",
    "    rel_model = []\n",
    "    for w in coll[docno]:\n",
    "        model.append(prob_func(dictTF_alldocs, coll, w, docno, lamb))\n",
    "        rel_model.append(relevance_model(dictTF_alldocs, bm25, coll, w, query))\n",
    "    \n",
    "    #cross entropy\n",
    "    ce = np.sum(np.array(model) * np.log(np.array(rel_model)))\n",
    "    m = len(model)\n",
    "    return -1/m * ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "XwWHrO4o_K-Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7418,
     "status": "ok",
     "timestamp": 1681385365589,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "XwWHrO4o_K-Y",
    "outputId": "56fd95e2-afa7-4905-c1eb-d531c8915662"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/pyterrier/ops.py:190: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n",
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/pyterrier/ops.py:190: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n",
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/pyterrier/ops.py:190: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n",
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/pyterrier/ops.py:190: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n",
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/pyterrier/ops.py:190: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n",
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/pyterrier/ops.py:190: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n",
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/pyterrier/ops.py:190: FutureWarning: .transform() should be passed a dataframe. Use .search() to execute a single query.\n",
      "  res = self.transformer.transform(topics_and_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7077890952863548\n"
     ]
    }
   ],
   "source": [
    "print(rel_mod_retrieval(dictTF_alldocs, coll, queries['1'], '1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d01761-8aaf-4d70-91da-d54f54f3dc5b",
   "metadata": {
    "id": "21d01761-8aaf-4d70-91da-d54f54f3dc5b"
   },
   "source": [
    "# 3. EXPANSION PREDICTION TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423c945-03c5-4ab8-9075-ff5191ff4713",
   "metadata": {
    "id": "9423c945-03c5-4ab8-9075-ff5191ff4713"
   },
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "779ba006-d870-42ce-99da-fa9880997014",
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1681385365590,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "779ba006-d870-42ce-99da-fa9880997014"
   },
   "outputs": [],
   "source": [
    "def all_P_wQ(vocab, dictTF, coll, query):\n",
    "    return np.array([relevance_model(dictTF, coll, w, query) for w in vocab])\n",
    "\n",
    "def P_wColl(term, coll):\n",
    "    return p_ml_coll(term, coll) # P(w|coll) = frequency of term in the entire collection, as well as P_ML(w|coll)\n",
    "\n",
    "def all_P_wcoll(vocab, coll):\n",
    "    return np.array([P_wColl(w, coll) for w in vocab])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1635187-b313-4fc1-acdf-c48eeb67b1a3",
   "metadata": {
    "id": "c1635187-b313-4fc1-acdf-c48eeb67b1a3"
   },
   "source": [
    "## 3.1 CLARITY METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ef64d-2b73-4bd0-9178-d6b7e3589145",
   "metadata": {
    "id": "1e1ef64d-2b73-4bd0-9178-d6b7e3589145"
   },
   "source": [
    "### Weighted clarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "de804825-d7a9-4e1d-816a-116e0a383a66",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1681385365591,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "de804825-d7a9-4e1d-816a-116e0a383a66"
   },
   "outputs": [],
   "source": [
    "def u(w, query, gamma):  # u == func which defines each weight of w\n",
    "    if w in query:\n",
    "        return gamma\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1bc969e4-f4c7-4384-aa1b-14ada4477271",
   "metadata": {
    "id": "1bc969e4-f4c7-4384-aa1b-14ada4477271"
   },
   "outputs": [],
   "source": [
    "def clarity(u, dictTF, coll, query, gamma): # u == func which defines each weight of w\n",
    "    vocabulary = list(dictTF.keys())\n",
    "    P_WQ = all_P_wQ(vocabulary, dictTF, coll, query)\n",
    "    P_WColl = all_P_wcoll(vocabulary, coll)\n",
    "    u_W = np.array([u(w, query, gamma) for w in vocabulary])\n",
    "    E_AU = np.sum(u_W * P_WQ)\n",
    "    return np.sum((u_W * P_WQ / E_AU) * np.log2(P_WQ / P_WColl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c8c5f62-1a76-41cf-88da-e2be3cee15b4",
   "metadata": {
    "id": "64eaff98-0777-477a-8f81-22107f40449f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/numpy/core/function_base.py:277: RuntimeWarning: overflow encountered in power\n",
      "  return _nx.power(base, y)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [71], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr \u001b[38;5;66;03m# Rank correlation, chosen arbitrarly\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gammas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1e7\u001b[39m, \u001b[38;5;241m29\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m clarities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([clarity(u, dictTF_alldocs, coll, query, gamma) \u001b[38;5;28;01mfor\u001b[39;00m gamma \u001b[38;5;129;01min\u001b[39;00m gammas]) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries])\n",
      "Cell \u001b[0;32mIn [71], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr \u001b[38;5;66;03m# Rank correlation, chosen arbitrarly\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gammas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1e7\u001b[39m, \u001b[38;5;241m29\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m clarities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([clarity(u, dictTF_alldocs, coll, query, gamma) \u001b[38;5;28;01mfor\u001b[39;00m gamma \u001b[38;5;129;01min\u001b[39;00m gammas]) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries])\n",
      "Cell \u001b[0;32mIn [71], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr \u001b[38;5;66;03m# Rank correlation, chosen arbitrarly\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gammas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1e7\u001b[39m, \u001b[38;5;241m29\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m clarities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([\u001b[43mclarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m gamma \u001b[38;5;129;01min\u001b[39;00m gammas]) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries])\n",
      "Cell \u001b[0;32mIn [70], line 3\u001b[0m, in \u001b[0;36mclarity\u001b[0;34m(u, dictTF, coll, query, gamma)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclarity\u001b[39m(u, dictTF, coll, query, gamma): \u001b[38;5;66;03m# u == func which defines each weight of w\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dictTF\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m----> 3\u001b[0m     P_WQ \u001b[38;5;241m=\u001b[39m \u001b[43mall_P_wQ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictTF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     P_WColl \u001b[38;5;241m=\u001b[39m all_P_wcoll(vocabulary, coll)\n\u001b[1;32m      5\u001b[0m     u_W \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([u(w, query, gamma) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m vocabulary])\n",
      "Cell \u001b[0;32mIn [68], line 2\u001b[0m, in \u001b[0;36mall_P_wQ\u001b[0;34m(vocab, dictTF, coll, query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_P_wQ\u001b[39m(vocab, dictTF, coll, query):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([relevance_model(dictTF, coll, w,query) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m vocab])\n",
      "Cell \u001b[0;32mIn [68], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_P_wQ\u001b[39m(vocab, dictTF, coll, query):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mrelevance_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m vocab])\n",
      "Cell \u001b[0;32mIn [64], line 7\u001b[0m, in \u001b[0;36mrelevance_model\u001b[0;34m(dictTF_alldocs, coll, w, query, prob_func, lamb)\u001b[0m\n\u001b[1;32m      5\u001b[0m score_top50 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m docno \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(coll\u001b[38;5;241m.\u001b[39mkeys())[:\u001b[38;5;241m200\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     score_top50\u001b[38;5;241m.\u001b[39mappend((docno, \u001b[43mbayes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      8\u001b[0m score_top50\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m score_top50 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(score_top50[:\u001b[38;5;241m50\u001b[39m])\n",
      "Cell \u001b[0;32mIn [59], line 3\u001b[0m, in \u001b[0;36mbayes\u001b[0;34m(dictTF_alldocs, coll, query, docno, prob_func)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbayes\u001b[39m(dictTF_alldocs, coll, query, docno, prob_func \u001b[38;5;241m=\u001b[39m dirichlet_smoothing): \n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_likelihood_retr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_func\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(coll)\n",
      "Cell \u001b[0;32mIn [56], line 3\u001b[0m, in \u001b[0;36mquery_likelihood_retr\u001b[0;34m(dictTF_alldocs, coll, query, docno, prob_func)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_likelihood_retr\u001b[39m(dictTF_alldocs, coll, query, docno, prob_func \u001b[38;5;241m=\u001b[39m dirichlet_smoothing): \u001b[38;5;66;03m# P(Q|D)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mprod(np\u001b[38;5;241m.\u001b[39marray([prob_func(dictTF_alldocs, coll, term, docno) \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query]))\n",
      "Cell \u001b[0;32mIn [56], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_likelihood_retr\u001b[39m(dictTF_alldocs, coll, query, docno, prob_func \u001b[38;5;241m=\u001b[39m dirichlet_smoothing): \u001b[38;5;66;03m# P(Q|D)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mprod(np\u001b[38;5;241m.\u001b[39marray([\u001b[43mprob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query]))\n",
      "Cell \u001b[0;32mIn [55], line 3\u001b[0m, in \u001b[0;36mdirichlet_smoothing\u001b[0;34m(dictTF_alldocs, coll, w, docno, mu)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdirichlet_smoothing\u001b[39m(dictTF_alldocs, coll, w, docno, mu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m      2\u001b[0m     lamb \u001b[38;5;241m=\u001b[39m term_occ(coll, docno) \u001b[38;5;241m/\u001b[39m (term_occ(coll, docno) \u001b[38;5;241m+\u001b[39m mu)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msmoothing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [54], line 2\u001b[0m, in \u001b[0;36msmoothing\u001b[0;34m(dictTF_alldocs, coll, w, docno, lamb)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msmoothing\u001b[39m(dictTF_alldocs, coll, w, docno, lamb): \u001b[38;5;66;03m# P(w|D)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lamb \u001b[38;5;241m*\u001b[39m p_ml(dictTF_alldocs, coll, w, docno) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lamb) \u001b[38;5;241m*\u001b[39m \u001b[43mp_ml_coll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [53], line 4\u001b[0m, in \u001b[0;36mp_ml_coll\u001b[0;34m(dictTF_alldocs, coll, w)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_ml_coll\u001b[39m(dictTF_alldocs, coll, w):\n\u001b[1;32m      3\u001b[0m     sum_tf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m docno \u001b[38;5;129;01min\u001b[39;00m coll\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m coll[docno]:\n\u001b[1;32m      6\u001b[0m             sum_tf \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dictTF_alldocs[docno][w]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr # Rank correlation, chosen arbitrarly\n",
    "\n",
    "gammas = np.logspace(0.1, 1e7, 29)\n",
    "clarities = np.array([np.array([clarity(u, dictTF_alldocs, coll, query, gamma) for gamma in gammas]) for query in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "355c5335-4f2f-46b5-9dee-86a8a6a1d90f",
   "metadata": {
    "id": "64eaff98-0777-477a-8f81-22107f40449f"
   },
   "outputs": [],
   "source": [
    "qldr = np.array([np.array([query_likelihood_retr(dictTF_alldocs, coll, query, docno, prob_func = dirichlet_smoothing) for doc in coll]) for query in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c727784b-f850-4a19-979b-55601780162b",
   "metadata": {
    "id": "64eaff98-0777-477a-8f81-22107f40449f"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr \u001b[38;5;66;03m# Rank correlation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gammas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1e7\u001b[39m, \u001b[38;5;241m29\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m clarities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([clarity(u, dictTF_alldocs, coll, coll, query, gamma) \u001b[38;5;28;01mfor\u001b[39;00m gamma \u001b[38;5;129;01min\u001b[39;00m gammas]) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries])\n\u001b[1;32m      5\u001b[0m qldr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([query_likelihood_retr(query, doc, dirichlet_smoothing) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries]) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m coll])\n",
      "Cell \u001b[0;32mIn [41], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr \u001b[38;5;66;03m# Rank correlation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gammas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1e7\u001b[39m, \u001b[38;5;241m29\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m clarities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([clarity(u, dictTF_alldocs, coll, coll, query, gamma) \u001b[38;5;28;01mfor\u001b[39;00m gamma \u001b[38;5;129;01min\u001b[39;00m gammas]) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries])\n\u001b[1;32m      5\u001b[0m qldr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([query_likelihood_retr(query, doc, dirichlet_smoothing) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries]) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m coll])\n",
      "Cell \u001b[0;32mIn [41], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr \u001b[38;5;66;03m# Rank correlation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gammas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1e7\u001b[39m, \u001b[38;5;241m29\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m clarities \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([\u001b[43mclarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m gamma \u001b[38;5;129;01min\u001b[39;00m gammas]) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries])\n\u001b[1;32m      5\u001b[0m qldr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray([query_likelihood_retr(query, doc, dirichlet_smoothing) \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m queries]) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m coll])\n",
      "Cell \u001b[0;32mIn [40], line 3\u001b[0m, in \u001b[0;36mclarity\u001b[0;34m(u, dictTF_top50, top50, coll, query, gamma)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclarity\u001b[39m(u, dictTF_top50, top50, coll, query, gamma): \u001b[38;5;66;03m# u == func which defines each weight of w\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(top_vocab(coll, {})\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m----> 3\u001b[0m     P_WQ \u001b[38;5;241m=\u001b[39m \u001b[43mall_P_wQ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdictTF_top50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     P_WColl \u001b[38;5;241m=\u001b[39m all_P_wcoll(vocabulary, query)\n\u001b[1;32m      5\u001b[0m     u_W \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([u(w, query, gamma) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m vocabulary])\n",
      "Cell \u001b[0;32mIn [38], line 2\u001b[0m, in \u001b[0;36mall_P_wQ\u001b[0;34m(vocab, dictTF_top50, top50, query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_P_wQ\u001b[39m(vocab, dictTF_top50, top50, query):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([relevance_model(dictTF_top50, top50, w,query) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m vocab])\n",
      "Cell \u001b[0;32mIn [38], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_P_wQ\u001b[39m(vocab, dictTF_top50, top50, query):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mrelevance_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_top50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m vocab])\n",
      "Cell \u001b[0;32mIn [27], line 7\u001b[0m, in \u001b[0;36mrelevance_model\u001b[0;34m(dictTF_alldocs, coll, w, query, prob_func, lamb)\u001b[0m\n\u001b[1;32m      5\u001b[0m score_top50 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m docno \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(coll\u001b[38;5;241m.\u001b[39mkeys())[:\u001b[38;5;241m200\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     score_top50\u001b[38;5;241m.\u001b[39mappend((docno, \u001b[43mbayes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      8\u001b[0m score_top50\u001b[38;5;241m.\u001b[39msort(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m a: a[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m score_top50 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(score_top50[:\u001b[38;5;241m50\u001b[39m])\n",
      "Cell \u001b[0;32mIn [19], line 3\u001b[0m, in \u001b[0;36mbayes\u001b[0;34m(dictTF_alldocs, coll, query, docno, prob_func)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbayes\u001b[39m(dictTF_alldocs, coll, query, docno, prob_func \u001b[38;5;241m=\u001b[39m dirichlet_smoothing): \n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_likelihood_retr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob_func\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(coll)\n",
      "Cell \u001b[0;32mIn [15], line 3\u001b[0m, in \u001b[0;36mquery_likelihood_retr\u001b[0;34m(dictTF_alldocs, coll, query, docno, prob_func)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_likelihood_retr\u001b[39m(dictTF_alldocs, coll, query, docno, prob_func \u001b[38;5;241m=\u001b[39m dirichlet_smoothing): \u001b[38;5;66;03m# P(Q|D)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mprod(np\u001b[38;5;241m.\u001b[39marray([prob_func(dictTF_alldocs, coll, term, docno) \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query]))\n",
      "Cell \u001b[0;32mIn [15], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery_likelihood_retr\u001b[39m(dictTF_alldocs, coll, query, docno, prob_func \u001b[38;5;241m=\u001b[39m dirichlet_smoothing): \u001b[38;5;66;03m# P(Q|D)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mprod(np\u001b[38;5;241m.\u001b[39marray([\u001b[43mprob_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query]))\n",
      "Cell \u001b[0;32mIn [14], line 3\u001b[0m, in \u001b[0;36mdirichlet_smoothing\u001b[0;34m(dictTF_alldocs, coll, w, docno, mu)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdirichlet_smoothing\u001b[39m(dictTF_alldocs, coll, w, docno, mu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m      2\u001b[0m     lamb \u001b[38;5;241m=\u001b[39m term_occ(coll, docno) \u001b[38;5;241m/\u001b[39m (term_occ(coll, docno) \u001b[38;5;241m+\u001b[39m mu)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msmoothing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [13], line 2\u001b[0m, in \u001b[0;36msmoothing\u001b[0;34m(dictTF_alldocs, coll, w, docno, lamb)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msmoothing\u001b[39m(dictTF_alldocs, coll, w, docno, lamb): \u001b[38;5;66;03m# P(w|D)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lamb \u001b[38;5;241m*\u001b[39m p_ml(dictTF_alldocs, coll, w, docno) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lamb) \u001b[38;5;241m*\u001b[39m \u001b[43mp_ml_coll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictTF_alldocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [12], line 4\u001b[0m, in \u001b[0;36mp_ml_coll\u001b[0;34m(dictTF_alldocs, coll, w)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_ml_coll\u001b[39m(dictTF_alldocs, coll, w):\n\u001b[1;32m      3\u001b[0m     sum_tf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m docno \u001b[38;5;129;01min\u001b[39;00m coll\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m coll[docno]:\n\u001b[1;32m      6\u001b[0m             sum_tf \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dictTF_alldocs[docno][w]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = spearmanr(clarities, b=qldr, axis=None)\n",
    "R = res.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed549d5-0d30-4dad-a738-bd0bc607ac8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "g28TXe-B1rJr",
   "metadata": {
    "id": "g28TXe-B1rJr"
   },
   "source": [
    "## 3.2 Overlap Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GW_D-ChP1wbu",
   "metadata": {
    "id": "GW_D-ChP1wbu"
   },
   "source": [
    "On prend les n ( = 100 dans l'article) meilleurs documents pour la requête non étendu et les 100 meilleurs pour la requête étendue et on garde l'intersection.\n",
    "Si jai bien comprus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JSSwNuEbZX4J",
   "metadata": {
    "id": "JSSwNuEbZX4J"
   },
   "source": [
    "Pour une requete ce serait :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "-8pKq2ymZaT8",
   "metadata": {
    "executionInfo": {
     "elapsed": 26013,
     "status": "ok",
     "timestamp": 1681386461600,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "-8pKq2ymZaT8"
   },
   "outputs": [],
   "source": [
    "#1 Meilleurs doc parmi les 2 premiers pour la query 1 avec unexpanded expanded. (POUR TESTS)\n",
    "unexpanded = []\n",
    "expanded = []\n",
    "for docno in coll.keys():\n",
    "    if(int(docno)>2):\n",
    "        break\n",
    "    unexpanded.append((docno, query_likelihood_retr(dictTF_alldocs, coll, queries['1'], docno)))\n",
    "    expanded.append((docno, rel_mod_retrieval(dictTF_alldocs, coll, queries['1'], docno)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "O0Hrdd89bhvQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1681386625636,
     "user": {
      "displayName": "Prénom Nom",
      "userId": "00284320685744777734"
     },
     "user_tz": -120
    },
    "id": "O0Hrdd89bhvQ",
    "outputId": "c6fb228c-f008-4127-dfa2-1f75fc41602d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2', 1.5367674491879992e-19)]\n",
      "[('2', 0.5491576932354653)]\n",
      "['2']\n"
     ]
    }
   ],
   "source": [
    "unexpanded.sort(key=lambda a: a[1])\n",
    "expanded.sort(key=lambda a: a[1])\n",
    "\n",
    "expanded = expanded[:1]\n",
    "unexpanded = unexpanded[:1]\n",
    "\n",
    "overlap = []\n",
    "for d1 in unexpanded:\n",
    "    for d2 in expanded:\n",
    "        if d1[0] == d2[0]: # On regarde si un doc de expanded est dans unexpanded, si oui on le garde\n",
    "            overlap.append(d1[0])\n",
    "        break\n",
    "\n",
    "print(unexpanded)\n",
    "print(expanded)\n",
    "print(overlap)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
